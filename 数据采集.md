import random
import csv
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException
import time
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# 手动指定 ChromeDriver 路径
chrome_driver_path = "C:/Users/联想/Desktop/王忠文/chromedriver-win64/chromedriver.exe"

# 手动维护的 User-Agent 列表
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    # ... 其他 User-Agent 保持不变 ...
]

# 存储所有商品数据的列表
all_products = []

# 颜色关键词列表
color_keywords = ['红', '蓝', '黑', '白', '金', '银', '灰', '绿', '粉', '紫', '青', '橙', '黛', '褐', '驼', '茶', '钛',
                  '岩', '玉', '瓷', '砂', '雾', '夜', '日', '月', '星', '空']

# 运行内存匹配正则表达式
ram_patterns = [
    r'(\d+)\s*[Gg][Bb]\s*[+]\s*(\d+)\s*[TtGg][Bb]',  # 匹配 8GB+256GB、16GB+1TB 等格式
    r'(\d+)\s*[Gg][Bb]',  # 匹配 8GB、12GB 等格式
]

# 电池容量匹配正则表达式
battery_patterns = [
    r'(\d+)\s*m[Aa][Hh]',  # 匹配 5000mAh、4500 mAh 等格式
]

# 屏幕尺寸匹配正则表达式
screen_size_patterns = [
    r'(\d+\.?\d*)\s*[英寸寸]',  # 匹配 6.7英寸、6.5寸等格式
]


def init_chrome_driver():
    # 保持不变
    chrome_options = Options()
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    user_agent = random.choice(USER_AGENTS)
    chrome_options.add_argument(f'user-agent={user_agent}')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    service = Service(chrome_driver_path)
    driver = webdriver.Chrome(service=service, options=chrome_options)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """
    })
    return driver


# 尝试多种选择器定位商品列表（保持不变）
def locate_goods_list(driver):
    selectors = [".J-goods-list", "div[class*='goods-list']"]
    for selector in selectors:
        try:
            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
            logging.info(f"使用选择器 '{selector}' 成功定位到商品列表")
            return driver.find_elements(By.CSS_SELECTOR, f"{selector} li.gl-item")
        except:
            logging.warning(f"选择器 '{selector}' 定位失败")
    return []


# 提取颜色（保持不变）
def extract_color(title):
    title_lower = title.lower()
    for color in color_keywords:
        if color.lower() in title_lower:
            return color
    return "未知"


# 提取运行内存（保持不变）
def extract_ram(title):
    for pattern in ram_patterns:
        match = re.search(pattern, title)
        if match:
            return match.group(0)
    return "未知"


# 提取电池容量（保持不变）
def extract_battery(title):
    for pattern in battery_patterns:
        match = re.search(pattern, title)
        if match:
            return match.group(0)
    return "未知"


# 新增：提取屏幕尺寸
def extract_screen_size(title):
    for pattern in screen_size_patterns:
        match = re.search(pattern, title)
        if match:
            return match.group(0)
    return "未知"


# 新增：提取型号（从标题中切割品牌后的部分）
def extract_model(title):
    brand_list = ['华为', '苹果', '小米', 'OPPO', 'vivo', '荣耀', '三星', '一加', 'realme']
    for brand in brand_list:
        if brand in title:
            return title.replace(brand, '').strip()
    return "未知"


# 新增：提取好评率（列表页可能存在的 .p-commit 元素）
def extract_好评率(item):
    try:
        commit_elem = item.find_element(By.CSS_SELECTOR, ".p-commit strong")
        return commit_elem.text.strip()
    except:
        return "未知"


def crawl_jd_page(driver, page_url, page_num):
    max_retries = 3
    for retry in range(max_retries):
        try:
            logging.info(f"正在爬取第{page_num}页 (尝试 {retry + 1}/{max_retries}): {page_url}")
            driver.get(page_url)
            WebDriverWait(driver, 30).until(lambda d: d.execute_script('return document.readyState') == 'complete')

            # 随机滚动页面（保持不变）
            scroll_height = driver.execute_script("return document.body.scrollHeight")
            for _ in range(random.randint(3, 6)):
                driver.execute_script(f"window.scrollTo(0, {random.randint(0, scroll_height)});")
                time.sleep(random.uniform(0.5, 1.5))

            product_items = locate_goods_list(driver)
            if not product_items:
                logging.error(f"第{page_num}页未找到商品，可能被反爬拦截")
                driver.save_screenshot(f"error_page_{page_num}_retry_{retry + 1}.png")
                raise Exception("未找到商品列表元素")

            logging.info(f"第{page_num}页共找到{len(product_items)}个商品")
            page_products = []

            for item in product_items[:30]:
                product_data = {
                    'page': page_num,
                    'title': '未知',
                    'price': '0.00',
                    'color': '未知',
                    'ram': '未知',
                    'battery': '未知',
                    'screen_size': '未知',
                    'model': '未知',
                    '好评率': '未知',
                    'link': ''
                }

                try:
                    # 提取基础信息
                    title = item.find_element(By.CSS_SELECTOR, ".p-name a em").text.strip()
                    price = item.find_element(By.CSS_SELECTOR, ".p-price i").text
                    link = item.find_element(By.CSS_SELECTOR, ".p-name a").get_attribute("href")

                    # 提取新增字段
                    screen_size = extract_screen_size(title)
                    model = extract_model(title)
                    comment_rate = extract_好评率(item)

                    # 填充数据字典
                    product_data.update({
                        'title': title,
                        'price': price,
                        'color': extract_color(title),
                        'ram': extract_ram(title),
                        'battery': extract_battery(title),
                        'screen_size': screen_size,
                        'model': model,
                        '好评率': comment_rate,
                        'link': link
                    })

                    logging.info(
                        f"商品: {title[:30]}..., 价格: {price}, 型号: {model}, 屏幕尺寸: {screen_size}, 好评率: {comment_rate}")

                except Exception as e:
                    logging.warning(f"解析商品时出错: {e}")

                page_products.append(product_data)

            all_products.extend(page_products)
            logging.info(f"第{page_num}页成功提取{len(page_products)}条数据")
            return True

        except TimeoutException:
            logging.error(f"第{page_num}页加载超时")
            driver.save_screenshot(f"timeout_page_{page_num}_retry_{retry + 1}.png")
        except WebDriverException as e:
            logging.error(f"WebDriver异常: {e}")
        except Exception as e:
            logging.error(f"未知异常: {e}")
            import traceback
            logging.error(traceback.format_exc())

        wait_time = random.uniform(5 * (retry + 1), 10 * (retry + 1))
        logging.info(f"等待{wait_time:.2f}秒后重试...")
        time.sleep(wait_time)

    logging.error(f"第{page_num}页爬取失败，已达到最大重试次数")
    return False


# 保存CSV（新增字段）
def save_to_csv(filename='jd_products.csv'):
    if not all_products:
        logging.warning("没有数据可保存")
        return

    fieldnames = ['page', 'title', 'price', 'color', 'ram', 'battery', 'screen_size', 'model', '好评率', 'link']
    try:
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_products)
        logging.info(f"成功保存{len(all_products)}条数据到{filename}")
    except Exception as e:
        logging.error(f"保存CSV失败: {e}")


def main():
    driver = init_chrome_driver()
    try:
        base_url = "https://list.jd.com/list.html?cat=9987,653,655"
        for page_num in range(1, 50):
            page_url = f"{base_url}&page={page_num}"
            success = crawl_jd_page(driver, page_url, page_num)

            wait_time = random.uniform(8, 15)
            logging.info(f"等待 {wait_time:.2f} 秒后继续...")
            time.sleep(wait_time)

            if page_num % 5 == 0:
                save_to_csv(f'jd_products_page_{page_num}.csv')

        save_to_csv('jd_products_complete.csv')

    finally:
        if driver:
            driver.quit()


if __name__ == "__main__":
    main()
